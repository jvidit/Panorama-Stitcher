{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from statistics import median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "nImages = None\n",
    "imageSetNumber = 4\n",
    "kFirstMatches = 2\n",
    "\n",
    "nKeyPointsInitial = 15000\n",
    "goodMatchRatio = 0.7\n",
    "\n",
    "histogramEqualizationWIndowSize = (2,2)\n",
    "xParameter=2.0\n",
    "\n",
    "BlurTuple = (5,5)\n",
    "\n",
    "resizeFactor = 5\n",
    "resizeTuple = (4160//resizeFactor, 2340//resizeFactor)\n",
    "\n",
    "\n",
    "k = 100\n",
    "ScaleCorrection = [[k,0,0],[0,k,0],[0,0,1]]\n",
    "\n",
    "\n",
    "HomographyInOrder = []\n",
    "centerImageIndex = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSetPath = \"./In-Sample/\"+str(imageSetNumber)+\"/\"\n",
    "\n",
    "\n",
    "images = [ cv2.imread((imageSetPath+image)) for image in os.listdir(imageSetPath) if image[-3:]==\"jpg\"]\n",
    "nImages = len(images)\n",
    "# for i in range(len(images)) :\n",
    "#     images[i] = cv2.cvtColor(images[i], cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# print(len(images))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(images)):\n",
    "    blur = cv2.blur(images[i], BlurTuple)\n",
    "    images[i] = cv2.resize(blur,resizeTuple)\n",
    "\n",
    "centerImageIndex = len(images)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Laplacian_Pyramid_Blending_with_mask(A, B, m, num_levels = 6):\n",
    "    # assume mask is float32 [0,1]\n",
    "\n",
    "    #A, B, m have values 0-255\n",
    "    k = 2**num_levels\n",
    "    A = A[:(A.shape[0]//k)*k, :(A.shape[1]//k)*k,:]\n",
    "    B = B[:(B.shape[0]//k)*k, :(B.shape[1]//k)*k,:]\n",
    "    m = m[:(m.shape[0]//k)*k, :(m.shape[1]//k)*k,:]\n",
    "    print(\"A max, min ==\", np.amax(A), np.amin(A))\n",
    "    print(\"B max, min ==\", np.amax(B), np.amin(B))\n",
    "    print(\"m max, min ==\", np.amax(m), np.amin(m))\n",
    "    A = A/255\n",
    "    B = B/255\n",
    "    m = m/255\n",
    "    print(\"A_scaled max, min ==\", np.amax(A), np.amin(A))\n",
    "    print(\"B_scaled max, min ==\", np.amax(B), np.amin(B))\n",
    "    print(\"m_scaled max, min ==\", np.amax(m), np.amin(m))\n",
    "    \n",
    "    # generate Gaussian pyramid for A,B and mask\n",
    "    GA = A.copy()\n",
    "    GB = B.copy()\n",
    "    GM = m.copy()\n",
    "    gpA = [GA]\n",
    "    gpB = [GB]\n",
    "    gpM = [GM]\n",
    "    for i in range(num_levels):\n",
    "        GA = cv2.pyrDown(GA)\n",
    "        GB = cv2.pyrDown(GB)\n",
    "        GM = cv2.pyrDown(GM)\n",
    "        gpA.append(np.float32(GA))\n",
    "        gpB.append(np.float32(GB))\n",
    "        gpM.append(np.float32(GM))\n",
    "\n",
    "    # generate Laplacian Pyramids for A,B and masks\n",
    "    lpA  = [gpA[num_levels-1]] # the bottom of the Lap-pyr holds the last (smallest) Gauss level\n",
    "    lpB  = [gpB[num_levels-1]]\n",
    "    gpMr = [gpM[num_levels-1]]\n",
    "    for i in range(num_levels-1,0,-1):\n",
    "        # Laplacian: subtarct upscaled version of lower level from current level\n",
    "        # to get the high frequencies\n",
    "        LA = np.subtract(gpA[i-1], cv2.pyrUp(gpA[i]))\n",
    "        LB = np.subtract(gpB[i-1], cv2.pyrUp(gpB[i]))\n",
    "        lpA.append(LA)\n",
    "        lpB.append(LB)\n",
    "        gpMr.append(gpM[i-1]) # also reverse the masks\n",
    "\n",
    "    # Now blend images according to mask in each level\n",
    "    LS = []\n",
    "    for la,lb,gm in zip(lpA,lpB,gpMr):\n",
    "#         laMin, laMax = np.amin(la), np.amax(la)\n",
    "#         lbMin, lbMax = np.amin(lb), np.amax(lb)\n",
    "#         gmMin, gmMax = np.amin(gm), np.amax(gm)\n",
    "\n",
    "#         la[True]-=laMin\n",
    "#         lb[True]-=lbMin\n",
    "#         gm[True]-=gmMin\n",
    "\n",
    "\n",
    "#         la = la/(laMax - laMin)\n",
    "#         lb = lb/(lbMax - lbMin)\n",
    "#         gm = gm/(gmMax - gmMin)\n",
    "\n",
    "        ls = (la * gm + lb * (1 - gm))\n",
    "        LS.append(ls*255)\n",
    "\n",
    "    # now reconstruct\n",
    "    ls_ = LS[0]\n",
    "    \n",
    "    for i in range(1,num_levels):\n",
    "        ls_ = cv2.pyrUp(ls_)\n",
    "        print(ls_.dtype, LS[i].dtype)\n",
    "        ls_ = (cv2.add(ls_, np.float32(LS[i])))#*0.5\n",
    "#     ls_ = ls_/num_levels\n",
    "    \n",
    "    print(\"ls_ max, min ==\",np.amax(ls_), np.amin(ls_))\n",
    "    ls_scaled = ls_.astype(np.uint8)\n",
    "    print(\"ls_scaled max, min ==\",np.amax(ls_scaled), np.amin(ls_scaled))\n",
    "    cv2.imwrite(\"ls_scaled.jpg\", ls_scaled)\n",
    "    return ls_scaled\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     A = cv2.imread(\"input1.png\",0)\n",
    "#     B = cv2.imread(\"input2.png\",0)\n",
    "#     m = np.zeros_like(A, dtype='float32')\n",
    "#     m[:,A.shape[1]/2:] = 1 # make the mask half-and-half\n",
    "#     lpb = Laplacian_Pyramid_Blending_with_mask(A, B, m, 5)\n",
    "#     cv2.imwrite(\"lpb.png\",lpb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatches(img1, img2):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = False)\n",
    "    orb = cv2.ORB_create(nfeatures=nKeyPointsInitial)\n",
    "\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(img2, None)\n",
    "    \n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=kFirstMatches)\n",
    "    matches = selectGoodMatches(matches)\n",
    "    \n",
    "#     print(\"matches list is:\", matches)\n",
    "    \n",
    "    return matches, keypoints1, keypoints2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOrdering(images):\n",
    "    global centerImageIndex\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = False)\n",
    "    orb = cv2.ORB_create(nfeatures=nKeyPointsInitial)\n",
    "    splitImages = []\n",
    "    for image in images:\n",
    "        cols = len(image[0])\n",
    "        splitImages.append(image[:,0:(cols//2),:])\n",
    "        splitImages.append(image[:,(cols//2):cols,:])\n",
    "    \n",
    "    images = splitImages\n",
    "    nImages=len(images)\n",
    "    \n",
    "    \n",
    "    maxIndices = None, None\n",
    "    maxMatches = []\n",
    "    \n",
    "\n",
    "    matchDictionary = {}\n",
    "    for i in range(nImages):\n",
    "        matchDictionary[i] = {}\n",
    "    \n",
    "    \n",
    "    keypoints = []\n",
    "    descriptors = []\n",
    "    \n",
    "    for image in images :\n",
    "        keypoints_orb, descriptors_orb = orb.detectAndCompute(image, None)\n",
    "        keypoints.append(keypoints_orb)\n",
    "        descriptors.append(descriptors_orb)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(nImages):\n",
    "        print(\"\\n\")\n",
    "        for j in range(i+1,nImages):\n",
    "            matches = bf.knnMatch(descriptors[i], descriptors[j], k=kFirstMatches)\n",
    "            matches = selectGoodMatches(matches)\n",
    "            matchDictionary[i][j] = matches\n",
    "            matchDictionary[j][i] = matches\n",
    "            print(i,j,len(matchDictionary[i][j]))\n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "    imageClusters = [[2*i, 2*i+1] for i in range(nImages//2)]\n",
    "    \n",
    "    for n in range(len(imageClusters),1,-1):\n",
    "        \n",
    "        closestClusters = None, None\n",
    "        maxMatch = 0\n",
    "        \n",
    "        print(imageClusters)\n",
    "        for i in range(len(imageClusters)):\n",
    "            img1 = imageClusters[i][-1]\n",
    "            for j in range(len(imageClusters)):\n",
    "                if(i!=j):\n",
    "                    img2 = imageClusters[j][0]\n",
    "                    if(len(matchDictionary[img1][img2])>maxMatch):\n",
    "                        maxMatch = len(matchDictionary[img1][img2])\n",
    "                        closestClusters = i, j\n",
    "#         print(closestClusters)\n",
    "        ind1, ind2 = closestClusters\n",
    "        imageClusters[ind1]+=imageClusters[ind2]\n",
    "        del imageClusters[ind2]\n",
    "    \n",
    "    returnIndices = [imageClusters[0][i]//2 for i in range(0,len(imageClusters[0]),2)]\n",
    "    \n",
    "    n = len(returnIndices)\n",
    "    if(n%2!=0):\n",
    "        centerImageIndex = n//2;\n",
    "    else:\n",
    "        R = matchDictionary[returnIndices[0]*2 + 1][returnIndices[n//2]*2]\n",
    "        L = matchDictionary[returnIndices[n-1]*2][returnIndices[n//2 - 1]*2 + 1]\n",
    "        if(len(R)<len(L)):\n",
    "            centerImageIndex = n//2 - 1\n",
    "        else:\n",
    "            centerImageIndex = n//2\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    print(returnIndices)\n",
    "    return returnIndices, matchDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHomographyOrder(stitchOrder, images):\n",
    "    global HomographyInOrder\n",
    "    global centerImageIndex\n",
    "    for i in range(len(images)-1):\n",
    "        \n",
    "        matches, keypoints1, keypoints2 = getMatches(images[stitchOrder[i]], images[stitchOrder[i+1]])\n",
    "\n",
    "        print(\"shape of matches is:\", matches.shape)\n",
    "\n",
    "        src_pts = np.float32([ keypoints1[m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ keypoints2[m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "\n",
    "        print(len(src_pts),len(dst_pts))\n",
    "        \n",
    "        H, mask1 = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC,xParameter)\n",
    "        HomographyInOrder.append(H)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    for i in range(centerImageIndex+1,len(HomographyInOrder)):\n",
    "        HomographyInOrder[i]=HomographyInOrder[i-1]*HomographyInOrder[i]\n",
    "\n",
    "    HomographyInOrder[centerImageIndex-1] = np.linalg.inv(HomographyInOrder[centerImageIndex-1])\n",
    "    for i in range(centerImageIndex-2,-1,-1):\n",
    "        HomographyInOrder[i]=HomographyInOrder[i+1]*np.linalg.inv(HomographyInOrder[i])\n",
    "\n",
    "    return HomographyInOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectGoodMatches(matches):\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m in matches:\n",
    "        if m[0].distance < goodMatchRatio*m[1].distance:\n",
    "            good.append(m[0])\n",
    "    matches = np.asarray(good)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbEqualize(img):\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    # equalize the histogram of the Y channel\n",
    "#     img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=histogramEqualizationWIndowSize)\n",
    "    img_yuv[:,:,0] = clahe.apply(img_yuv[:,:,0])\n",
    "    # convert the YUV image back to RGB format\n",
    "    img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpTwoImages(img1, img2, H):\n",
    "    '''warp img2 to img1 with homograph H'''\n",
    "    \n",
    "    matches, keypoints1, keypoints2 = getMatches(img1, img2)\n",
    "    \n",
    "    print(\"shape of matches is:\", matches.shape)\n",
    "    \n",
    "    src_pts = np.float32([ keypoints1[m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ keypoints2[m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "\n",
    "    print(len(src_pts),len(dst_pts))\n",
    "    H, mask1 = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC,xParameter)\n",
    "    \n",
    "#     H = np.linalg.inv(ScaleCorrection)*H*ScaleCorrection\n",
    "#     Affine, inliners = cv2.estimateAffine2D(dst_pts, src_pts, method = cv2.RANSAC, ransacReprojThreshold = 1.0) \n",
    "#     Affine = cv2.estimateAffine3D(src_pts, dst_pts, ransacThreshold = 1.0) \n",
    "\n",
    "\n",
    "#     print(\"affine shape:\", type(Affine), len(Affine), Affine)\n",
    "#     Affine = np.append(Affine, [[0,0,1]], axis = 0)\n",
    "#     H=Affine\n",
    "#     print(H)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    h1,w1 = img1.shape[:2]\n",
    "    h2,w2 = img2.shape[:2]\n",
    "    pts1 = np.float32([[0,0],[0,h1],[w1,h1],[w1,0]]).reshape(-1,1,2)\n",
    "    pts2 = np.float32([[0,0],[0,h2],[w2,h2],[w2,0]]).reshape(-1,1,2)\n",
    "    pts2_ = cv2.perspectiveTransform(pts2, H)\n",
    "\n",
    "\n",
    "    \n",
    "    transformedPoints = pts2_.reshape(4,2)\n",
    "#     print(pts2_.reshape(4,2))\n",
    "    pts = np.concatenate((pts1, pts2_), axis=0)\n",
    "    [xmin, ymin] = np.int32(pts.min(axis=0).ravel() - 0.5)\n",
    "    [xmax, ymax] = np.int32(pts.max(axis=0).ravel() + 0.5)\n",
    "    t = [-xmin,-ymin]\n",
    "#     t = [min(0,-xmin),min(0,-ymin)]\n",
    "    Ht = np.array([[1,0,t[0]],[0,1,t[1]],[0,0,1]]) # translate\n",
    "    \n",
    "    \n",
    "    translatedPoints = [[point[0]+t[0],point[1]+t[1]] for point in transformedPoints]\n",
    "#     for point in transformedPoints:\n",
    "#         x,y = point\n",
    "#         temparray = [x+t[0], y+t[1]]\n",
    "#         translatedPoints.append(temparray)\n",
    "\n",
    "    \n",
    "    warpedImage = cv2.warpPerspective(img2, Ht.dot(H), (xmax-xmin, ymax-ymin))\n",
    "#     warpedImage = cv2.warpAffine(img2, Affine, (img2.shape[1], img2.shape[0]))\n",
    "    \n",
    "    mask = np.zeros(warpedImage.shape, dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, np.array([translatedPoints], dtype=np.int32), (255, 255, 255))\n",
    "    \n",
    "    result = np.zeros(warpedImage.shape, dtype=np.uint8)\n",
    "    result[t[1]:h1+t[1],t[0]:w1+t[0]] = img1\n",
    "    result[np.where(mask == 255)] = warpedImage[np.where(mask == 255)]\n",
    "    \n",
    "    A = warpedImage\n",
    "    B = result\n",
    "    m = mask\n",
    "    lpb = Laplacian_Pyramid_Blending_with_mask(A, B, m, 4)\n",
    "    result = lpb\n",
    "    \n",
    "    result = rgbEqualize(result)\n",
    "    print(\"result max, min==\", np.amax(result), np.amin(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeImages(images):\n",
    "    for i in range(nImages):\n",
    "        cv2.imwrite(\"log\"+str(i)+\".jpg\",images[i])\n",
    "        \n",
    "        \n",
    "# writeImages(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 1 3\n",
      "0 2 84\n",
      "0 3 9\n",
      "0 4 85\n",
      "0 5 600\n",
      "0 6 8\n",
      "0 7 467\n",
      "\n",
      "\n",
      "1 2 265\n",
      "1 3 19\n",
      "1 4 8\n",
      "1 5 21\n",
      "1 6 7\n",
      "1 7 2\n",
      "\n",
      "\n",
      "2 3 28\n",
      "2 4 11\n",
      "2 5 118\n",
      "2 6 3\n",
      "2 7 2\n",
      "\n",
      "\n",
      "3 4 6\n",
      "3 5 11\n",
      "3 6 5\n",
      "3 7 4\n",
      "\n",
      "\n",
      "4 5 0\n",
      "4 6 93\n",
      "4 7 528\n",
      "\n",
      "\n",
      "5 6 3\n",
      "5 7 58\n",
      "\n",
      "\n",
      "6 7 8\n",
      "\n",
      "\n",
      "[[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "[[2, 3], [4, 5, 0, 1], [6, 7]]\n",
      "[[2, 3], [6, 7, 4, 5, 0, 1]]\n",
      "[3, 2, 0, 1]\n",
      "shape of matches is: (1035,)\n",
      "1035 1035\n",
      "shape of matches is: (739,)\n",
      "739 739\n",
      "shape of matches is: (468,)\n",
      "468 468\n"
     ]
    }
   ],
   "source": [
    "stitchOrder, matches = getOrdering(images)\n",
    "HomographyInOrder = getHomographyOrder(stitchOrder, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "shape of matches is: (867,)\n",
      "867 867\n",
      "A max, min == 255 0\n",
      "B max, min == 255 0\n",
      "m max, min == 255 0\n",
      "A_scaled max, min == 1.0 0.0\n",
      "B_scaled max, min == 1.0 0.0\n",
      "m_scaled max, min == 1.0 0.0\n",
      "float32 float32\n",
      "float32 float32\n",
      "float32 float64\n",
      "ls_ max, min == 256.1417 -21.273628\n",
      "ls_scaled max, min == 255 0\n",
      "result max, min== 255 0\n"
     ]
    }
   ],
   "source": [
    "def horizontalStitch(stitchOrder, matches, images):\n",
    "#     stitchOrder, matches = getOrdering(images)\n",
    "    global centerImageIndex\n",
    "    global HomographyInOrder\n",
    "    orderedImages = []\n",
    "    for i in stitchOrder:\n",
    "        orderedImages.append(images[i])\n",
    "    \n",
    "    print(centerImageIndex)\n",
    "    \n",
    "#     img = orderedImages[centerImageIndex]\n",
    "#     for i in range(centerImageIndex+1,centerImageIndex+2):#len(orderedImages)):\n",
    "#         img = warpTwoImages(img, orderedImages[i])\n",
    "        \n",
    "#     for i in range(centerImageIndex-1,centerImageIndex-2,-1):#len(orderedImages)):\n",
    "#         img = warpTwoImages(img, orderedImages[i])\n",
    "    \n",
    "    \n",
    "#     return warpTwoImages(orderedImages[2],orderedImages[3],HomographyInOrder[-1])\n",
    "    \n",
    "    rightStitchedImage = stitchFromRight(orderedImages[centerImageIndex], orderedImages[centerImageIndex+1:], HomographyInOrder[centerImageIndex:])\n",
    "    \n",
    "    leftStitchedImage = stitchFromLeft(rightStitchedImage, orderedImages[:centerImageIndex], HomographyInOrder[:centerImageIndex]) \n",
    "    \n",
    "    return leftStitchedImage\n",
    "#     return img\n",
    "\n",
    "    \n",
    "def stitchFromRight(image, images, H):\n",
    "    if (len(images) == 1):\n",
    "        return image\n",
    "    warpedImg = warpTwoImages(image, images[0], H[0])\n",
    "    return stitchFromRight(warpedImg, images[1:], H[1:])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def stitchFromLeft(image, images, H):\n",
    "    if (len(images) == 1):\n",
    "        return image\n",
    "    warpedImg = warpTwoImages(image, images[-1], H[-1])\n",
    "    return stitchFromLeft(warpedImg, images[:-1], H[:-1])\n",
    "    \n",
    "\n",
    "result = horizontalStitch(stitchOrder, matches, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"affine-log.jpg\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0,2],[3,4]])\n",
    "b = np.array([[0,2],[3,4]])\n",
    "# a[True] -= 5\n",
    "# a=a/6\n",
    "print(b*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
