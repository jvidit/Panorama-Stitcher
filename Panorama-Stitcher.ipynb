{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "nKeyPointsInitial = 5000\n",
    "\n",
    "imageSetNumber = 1\n",
    "histogramEqualizationWIndowSize = (2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSetPath = \"./In-Sample/\"+str(imageSetNumber)+\"/\"\n",
    "\n",
    "images = [ cv2.imread((imageSetPath+image)) for image in os.listdir(imageSetPath)]\n",
    "\n",
    "# for i in range(len(images)) :\n",
    "#     images[i] = cv2.cvtColor(images[i], cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "keypoints = []\n",
    "descriptors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('img0', images[0])\n",
    "# cv2.imshow('img1', images[1])\n",
    "# cv2.imshow('img2', images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sift = cv2.xfeatures2d.SIFT_create()\n",
    "# surf = cv2.xfeatures2d.SURF_create()\n",
    "orb = cv2.ORB_create(nfeatures=nKeyPointsInitial)\n",
    "# fast = cv2.FastFeatureDetector_create(nKeyPointsInitial) \n",
    "# brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "\n",
    "# keypoints_sift, descriptors = sift.detectAndCompute(img, None)\n",
    "# keypoints_surf, descriptors = surf.detectAndCompute(img, None)\n",
    "\n",
    "\n",
    "for image in images :\n",
    "    keypoints_orb, descriptors_orb = orb.detectAndCompute(image, None)\n",
    "    keypoints.append(keypoints_orb)\n",
    "    descriptors.append(descriptors_orb)\n",
    "\n",
    "\n",
    "# keypoints_brief, descriptors_brief = brief.compute(img, None)\n",
    "# keypoints_fast = fast.detect(img, None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# img = cv2.drawKeypoints(img, keypoints_fast, None)\n",
    "# cv2.imwrite(\"1_1-out.jpg\",img)\n",
    "# cv2.imshow(\"Image\", img)\n",
    "# cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Brute Force Matcher object.\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "\n",
    "# Perform the matching between the BRIEF descriptors of the training image and the test image\n",
    "matches = bf.match(descriptors[1], descriptors[2])\n",
    "\n",
    "# The matches with shorter distance are the ones we want.\n",
    "matches = sorted(matches, key = lambda x : x.distance)\n",
    "\n",
    "result = cv2.drawMatches(images[1], keypoints[1], images[2], keypoints[2], matches, images[1], flags = 2)\n",
    "\n",
    "# cv2.imshow('res',result)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.imwrite(\"log.jpg\",result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src_pts = np.float32([ keypoints[1][m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ keypoints[2][m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "\n",
    "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "\n",
    "# matchesMask = mask.ravel().tolist()\n",
    "\n",
    "\n",
    "# h,w = images[1].shape\n",
    "# pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "# dst = cv2.perspectiveTransform(pts,M)\n",
    "\n",
    "\n",
    "# cv2.imwrite(\"log1.jpg\",images[2])\n",
    "\n",
    "# images[2] = cv2.polylines(images[2],[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "# cv2.imwrite(\"log2.jpg\",images[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbEqualize(img):\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    # equalize the histogram of the Y channel\n",
    "#     img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=histogramEqualizationWIndowSize)\n",
    "    img_yuv[:,:,0] = clahe.apply(img_yuv[:,:,0])\n",
    "    # convert the YUV image back to RGB format\n",
    "    img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpTwoImages(img1, img2, H):\n",
    "    '''warp img2 to img1 with homograph H'''\n",
    "    h1,w1 = img1.shape[:2]\n",
    "    h2,w2 = img2.shape[:2]\n",
    "    pts1 = np.float32([[0,0],[0,h1],[w1,h1],[w1,0]]).reshape(-1,1,2)\n",
    "    pts2 = np.float32([[0,0],[0,h2],[w2,h2],[w2,0]]).reshape(-1,1,2)\n",
    "    pts2_ = cv2.perspectiveTransform(pts2, H)\n",
    "    pts = np.concatenate((pts1, pts2_), axis=0)\n",
    "    [xmin, ymin] = np.int32(pts.min(axis=0).ravel() - 0.5)\n",
    "    [xmax, ymax] = np.int32(pts.max(axis=0).ravel() + 0.5)\n",
    "    t = [-xmin,-ymin]\n",
    "    Ht = np.array([[1,0,t[0]],[0,1,t[1]],[0,0,1]]) # translate\n",
    "\n",
    "    result = cv2.warpPerspective(img2, Ht.dot(H), (xmax-xmin, ymax-ymin))\n",
    "    result[t[1]:h1+t[1],t[0]:w1+t[0]] = img1\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "src_pts = np.float32([ keypoints[1][m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ keypoints[2][m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "\n",
    "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "\n",
    "result = warpTwoImages(images[2], images[1], M)\n",
    "result = rgbEqualize(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply panorama correction\n",
    "\n",
    "# width = images[1].shape[1] + images[2].shape[1]\n",
    "# height = images[1].shape[0] + images[2].shape[0]\n",
    "# result = cv2.warpPerspective(images[1], M, (width, height))\n",
    "# result[0:images[2].shape[0], 0:images[2].shape[1]] = images[2]\n",
    "\n",
    "cv2.imwrite(\"log2.jpg\",result)\n",
    "# cv2.imwrite(\"log1.jpg\",images[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/pyramids.cpp:880: error: (-215:Assertion failed) std::abs(dsize.width - ssize.width*2) == dsize.width % 2 && std::abs(dsize.height - ssize.height*2) == dsize.height % 2 in function 'pyrUp_'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-71b1f15294a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgpA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mGE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyrUp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdstsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.0) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/pyramids.cpp:880: error: (-215:Assertion failed) std::abs(dsize.width - ssize.width*2) == dsize.width % 2 && std::abs(dsize.height - ssize.height*2) == dsize.height % 2 in function 'pyrUp_'\n"
     ]
    }
   ],
   "source": [
    "A = images[2]\n",
    "B = images[1]\n",
    "\n",
    "# generate Gaussian pyramid for A\n",
    "G = A.copy()\n",
    "gpA = [G]\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    G = cv2.pyrDown(G)\n",
    "    gpA.append(G)\n",
    "\n",
    "# generate Gaussian pyramid for B\n",
    "G = B.copy()\n",
    "gpB = [G]\n",
    "for i in range(6):\n",
    "    G = cv2.pyrDown(G)\n",
    "    gpB.append(G)\n",
    "\n",
    "# generate Laplacian Pyramid for A\n",
    "lpA = [gpA[5]]\n",
    "for i in range(5,0,-1):\n",
    "    size = (gpA[i].shape[1], gpA[i].shape[0])\n",
    "    GE = cv2.pyrUp(gpA[i], dstsize = size)\n",
    "    print(type(gpB[i-1]), type(GE))\n",
    "    L = np.subtract(gpA[i-1],GE)\n",
    "    lpA.append(L)\n",
    "\n",
    "# generate Laplacian Pyramid for B\n",
    "lpB = [gpB[5]]\n",
    "for i in range(5,0,-1):\n",
    "    \n",
    "    GE = cv2.pyrUp(gpB[i], dstsize = size)\n",
    "    print(type(gpB[i-1]), type(GE))\n",
    "    L = np.subtract(gpB[i-1],GE)\n",
    "    \n",
    "    lpB.append(L)\n",
    "\n",
    "# Now add left and right halves of images in each level\n",
    "LS = []\n",
    "for la,lb in zip(lpA,lpB):\n",
    "    rows,cols,dpt = la.shape\n",
    "    ls = np.hstack((la[:,0:cols/2], lb[:,cols/2:]))\n",
    "    LS.append(ls)\n",
    "\n",
    "# now reconstruct\n",
    "ls_ = LS[0]\n",
    "for i in range(1,6):\n",
    "    ls_ = cv2.pyrUp(ls_)\n",
    "    ls_ = cv2.add(ls_, LS[i])\n",
    "\n",
    "# image with direct connecting each half\n",
    "real = np.hstack((A[:,:cols/2],B[:,cols/2:]))\n",
    "\n",
    "cv2.imwrite('Pyramid_blending2.jpg',ls_)\n",
    "cv2.imwrite('Direct_blending.jpg',real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
