{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "nKeyPointsInitial = 5000\n",
    "\n",
    "imageSetNumber = 1\n",
    "imageSetPath = \"./In-Sample/\"+str(imageSetNumber)+\"/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [ cv2.imread((imageSetPath+image)) for image in os.listdir(imageSetPath)]\n",
    "\n",
    "for i in range(len(images)) :\n",
    "    images[i] = cv2.cvtColor(images[i], cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "keypoints = []\n",
    "descriptors = []\n",
    "\n",
    "# print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = (cv2.imread(images[0]))\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# cv2.imshow('img0', images[0])\n",
    "# cv2.imshow('img1', images[1])\n",
    "# cv2.imshow('img2', images[2])\n",
    "\n",
    "# if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sift = cv2.xfeatures2d.SIFT_create()\n",
    "# surf = cv2.xfeatures2d.SURF_create()\n",
    "orb = cv2.ORB_create(nfeatures=nKeyPointsInitial)\n",
    "# fast = cv2.FastFeatureDetector_create(nKeyPointsInitial) \n",
    "# brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "\n",
    "\n",
    "\n",
    "# keypoints_sift, descriptors = sift.detectAndCompute(img, None)\n",
    "# keypoints_surf, descriptors = surf.detectAndCompute(img, None)\n",
    "\n",
    "\n",
    "for image in images :\n",
    "    keypoints_orb, descriptors_orb = orb.detectAndCompute(image, None)\n",
    "    keypoints.append(keypoints_orb)\n",
    "    descriptors.append(descriptors_orb)\n",
    "\n",
    "\n",
    "# keypoints_brief, descriptors_brief = brief.compute(img, None)\n",
    "# keypoints_fast = fast.detect(img, None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# img = cv2.drawKeypoints(img, keypoints_fast, None)\n",
    "# cv2.imwrite(\"1_1-out.jpg\",img)\n",
    "# cv2.imshow(\"Image\", img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Brute Force Matcher object.\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "\n",
    "# Perform the matching between the BRIEF descriptors of the training image and the test image\n",
    "matches = bf.match(descriptors[1], descriptors[2])\n",
    "\n",
    "# The matches with shorter distance are the ones we want.\n",
    "matches = sorted(matches, key = lambda x : x.distance)\n",
    "\n",
    "result = cv2.drawMatches(images[1], keypoints[1], images[2], keypoints[2], matches, images[1], flags = 2)\n",
    "\n",
    "# cv2.imshow('res',result)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.imwrite(\"log.jpg\",result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src_pts = np.float32([ keypoints[1][m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ keypoints[2][m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "\n",
    "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "\n",
    "# matchesMask = mask.ravel().tolist()\n",
    "\n",
    "\n",
    "# h,w = images[1].shape\n",
    "# pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "# dst = cv2.perspectiveTransform(pts,M)\n",
    "\n",
    "\n",
    "# cv2.imwrite(\"log1.jpg\",images[2])\n",
    "\n",
    "# images[2] = cv2.polylines(images[2],[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "# cv2.imwrite(\"log2.jpg\",images[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpTwoImages(img1, img2, H):\n",
    "    '''warp img2 to img1 with homograph H'''\n",
    "    h1,w1 = img1.shape[:2]\n",
    "    h2,w2 = img2.shape[:2]\n",
    "    pts1 = np.float32([[0,0],[0,h1],[w1,h1],[w1,0]]).reshape(-1,1,2)\n",
    "    pts2 = np.float32([[0,0],[0,h2],[w2,h2],[w2,0]]).reshape(-1,1,2)\n",
    "    pts2_ = cv2.perspectiveTransform(pts2, H)\n",
    "    pts = np.concatenate((pts1, pts2_), axis=0)\n",
    "    [xmin, ymin] = np.int32(pts.min(axis=0).ravel() - 0.5)\n",
    "    [xmax, ymax] = np.int32(pts.max(axis=0).ravel() + 0.5)\n",
    "    t = [-xmin,-ymin]\n",
    "    Ht = np.array([[1,0,t[0]],[0,1,t[1]],[0,0,1]]) # translate\n",
    "\n",
    "    result = cv2.warpPerspective(img2, Ht.dot(H), (xmax-xmin, ymax-ymin))\n",
    "    result[t[1]:h1+t[1],t[0]:w1+t[0]] = img1\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "src_pts = np.float32([ keypoints[1][m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ keypoints[2][m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "\n",
    "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "\n",
    "result = warpTwoImages(images[2], images[1], M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply panorama correction\n",
    "\n",
    "# width = images[1].shape[1] + images[2].shape[1]\n",
    "# height = images[1].shape[0] + images[2].shape[0]\n",
    "# result = cv2.warpPerspective(images[1], M, (width, height))\n",
    "# result[0:images[2].shape[0], 0:images[2].shape[1]] = images[2]\n",
    "\n",
    "cv2.imwrite(\"log2.jpg\",result)\n",
    "# cv2.imwrite(\"log1.jpg\",images[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
