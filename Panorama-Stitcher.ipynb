{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from statistics import median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nImages = None\n",
    "imageSetNumber = 4\n",
    "kFirstMatches = 2\n",
    "\n",
    "nKeyPointsInitial = 15000\n",
    "goodMatchRatio = 0.7\n",
    "\n",
    "histogramEqualizationWIndowSize = (2,2)\n",
    "xParameter=2.0\n",
    "\n",
    "BlurTuple = (5,5)\n",
    "\n",
    "resizeFactor = 5\n",
    "resizeTuple = (4160//resizeFactor, 2340//resizeFactor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSetPath = \"./In-Sample/\"+str(imageSetNumber)+\"/\"\n",
    "\n",
    "\n",
    "images = [ cv2.imread((imageSetPath+image)) for image in os.listdir(imageSetPath) if image[-3:]==\"jpg\"]\n",
    "nImages = len(images)\n",
    "# for i in range(len(images)) :\n",
    "#     images[i] = cv2.cvtColor(images[i], cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# print(len(images))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(images)):\n",
    "    blur = cv2.blur(images[i], BlurTuple)\n",
    "    images[i] = cv2.resize(blur,resizeTuple)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatches(img1, img2):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = False)\n",
    "    orb = cv2.ORB_create(nfeatures=nKeyPointsInitial)\n",
    "\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(img2, None)\n",
    "    \n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=kFirstMatches)\n",
    "    matches = selectGoodMatches(matches)\n",
    "    \n",
    "#     print(\"matches list is:\", matches)\n",
    "    \n",
    "    return matches, keypoints1, keypoints2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOrdering(images):\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = False)\n",
    "    orb = cv2.ORB_create(nfeatures=nKeyPointsInitial)\n",
    "    splitImages = []\n",
    "    for image in images:\n",
    "        cols = len(image[0])\n",
    "        splitImages.append(image[:,0:(cols//2),:])\n",
    "        splitImages.append(image[:,(cols//2):cols,:])\n",
    "    \n",
    "    images = splitImages\n",
    "    nImages=len(images)\n",
    "    \n",
    "    \n",
    "    maxIndices = None, None\n",
    "    maxMatches = []\n",
    "    \n",
    "\n",
    "    matchDictionary = {}\n",
    "    for i in range(nImages):\n",
    "        matchDictionary[i] = {}\n",
    "    \n",
    "    \n",
    "    keypoints = []\n",
    "    descriptors = []\n",
    "    \n",
    "    for image in images :\n",
    "        keypoints_orb, descriptors_orb = orb.detectAndCompute(image, None)\n",
    "        keypoints.append(keypoints_orb)\n",
    "        descriptors.append(descriptors_orb)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(nImages):\n",
    "        print(\"\\n\")\n",
    "        for j in range(i+1,nImages):\n",
    "            matches = bf.knnMatch(descriptors[i], descriptors[j], k=kFirstMatches)\n",
    "            matches = selectGoodMatches(matches)\n",
    "            matchDictionary[i][j] = matches\n",
    "            matchDictionary[j][i] = matches\n",
    "            print(i,j,len(matchDictionary[i][j]))\n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "    imageClusters = [[2*i, 2*i+1] for i in range(nImages//2)]\n",
    "    \n",
    "    for n in range(len(imageClusters),1,-1):\n",
    "        \n",
    "        closestClusters = None, None\n",
    "        maxMatch = 0\n",
    "        \n",
    "        print(imageClusters)\n",
    "        for i in range(len(imageClusters)):\n",
    "            img1 = imageClusters[i][-1]\n",
    "            for j in range(len(imageClusters)):\n",
    "                if(i!=j):\n",
    "                    img2 = imageClusters[j][0]\n",
    "                    if(len(matchDictionary[img1][img2])>maxMatch):\n",
    "                        maxMatch = len(matchDictionary[img1][img2])\n",
    "                        closestClusters = i, j\n",
    "#         print(closestClusters)\n",
    "        ind1, ind2 = closestClusters\n",
    "        imageClusters[ind1]+=imageClusters[ind2]\n",
    "        del imageClusters[ind2]\n",
    "    \n",
    "    returnIndices = [imageClusters[0][i]//2 for i in range(0,len(imageClusters[0]),2)]\n",
    "    print(returnIndices)\n",
    "    return returnIndices, matchDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectGoodMatches(matches):\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m in matches:\n",
    "        if m[0].distance < goodMatchRatio*m[1].distance:\n",
    "            good.append(m[0])\n",
    "    matches = np.asarray(good)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbEqualize(img):\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    # equalize the histogram of the Y channel\n",
    "#     img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=histogramEqualizationWIndowSize)\n",
    "    img_yuv[:,:,0] = clahe.apply(img_yuv[:,:,0])\n",
    "    # convert the YUV image back to RGB format\n",
    "    img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpTwoImages(img1, img2):\n",
    "    '''warp img2 to img1 with homograph H'''\n",
    "    \n",
    "    matches, keypoints1, keypoints2 = getMatches(img1, img2)\n",
    "    \n",
    "    print(\"shape of matches is:\", matches.shape)\n",
    "    \n",
    "    src_pts = np.float32([ keypoints1[m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ keypoints2[m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "\n",
    "    H, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC,xParameter)\n",
    "    \n",
    "    \n",
    "    h1,w1 = img1.shape[:2]\n",
    "    h2,w2 = img2.shape[:2]\n",
    "    pts1 = np.float32([[0,0],[0,h1],[w1,h1],[w1,0]]).reshape(-1,1,2)\n",
    "    pts2 = np.float32([[0,0],[0,h2],[w2,h2],[w2,0]]).reshape(-1,1,2)\n",
    "    pts2_ = cv2.perspectiveTransform(pts2, H)\n",
    "    transformedPoints = pts2_.reshape(4,2)\n",
    "#     print(pts2_.reshape(4,2))\n",
    "    pts = np.concatenate((pts1, pts2_), axis=0)\n",
    "    [xmin, ymin] = np.int32(pts.min(axis=0).ravel() - 0.5)\n",
    "    [xmax, ymax] = np.int32(pts.max(axis=0).ravel() + 0.5)\n",
    "    t = [-xmin,-ymin]\n",
    "    Ht = np.array([[1,0,t[0]],[0,1,t[1]],[0,0,1]]) # translate\n",
    "    \n",
    "    \n",
    "    translatedPoints = [[point[0]+t[0],point[1]+t[1]] for point in transformedPoints]\n",
    "#     for point in transformedPoints:\n",
    "#         x,y = point\n",
    "#         temparray = [x+t[0], y+t[1]]\n",
    "#         translatedPoints.append(temparray)\n",
    "\n",
    "    \n",
    "    warpedImage = cv2.warpPerspective(img2, Ht.dot(H), (xmax-xmin, ymax-ymin))\n",
    "    \n",
    "    \n",
    "    mask = np.zeros(warpedImage.shape, dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, np.array([translatedPoints], dtype=np.int32), (255, 255, 255))\n",
    "    \n",
    "    \n",
    "    result = np.zeros(warpedImage.shape, dtype=np.uint8)\n",
    "    result[t[1]:h1+t[1],t[0]:w1+t[0]] = img1\n",
    "    result[np.where(mask == 255)] = warpedImage[np.where(mask == 255)]\n",
    "    \n",
    "    \n",
    "    result = rgbEqualize(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeImages(images):\n",
    "    for i in range(nImages):\n",
    "        cv2.imwrite(\"log\"+str(i)+\".jpg\",images[i])\n",
    "        \n",
    "        \n",
    "writeImages(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 1 0\n",
      "0 2 0\n",
      "0 3 1\n",
      "0 4 0\n",
      "0 5 0\n",
      "0 6 2\n",
      "0 7 2\n",
      "\n",
      "\n",
      "1 2 0\n",
      "1 3 0\n",
      "1 4 6\n",
      "1 5 0\n",
      "1 6 0\n",
      "1 7 1\n",
      "\n",
      "\n",
      "2 3 0\n",
      "2 4 0\n",
      "2 5 0\n",
      "2 6 0\n",
      "2 7 1\n",
      "\n",
      "\n",
      "3 4 0\n",
      "3 5 0\n",
      "3 6 1\n",
      "3 7 0\n",
      "\n",
      "\n",
      "4 5 0\n",
      "4 6 1\n",
      "4 7 0\n",
      "\n",
      "\n",
      "5 6 1\n",
      "5 7 1\n",
      "\n",
      "\n",
      "6 7 0\n",
      "\n",
      "\n",
      "[[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "[[0, 1, 4, 5], [2, 3], [6, 7]]\n",
      "[[2, 3], [6, 7, 0, 1, 4, 5]]\n",
      "[1, 3, 0, 2]\n",
      "2\n",
      "shape of matches is: (7,)\n",
      "shape of matches is: (2,)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) /tmp/opencv-20190908-76835-1lnncvq/opencv-4.1.1/modules/core/src/matmul.dispatch.cpp:525: error: (-215:Assertion failed) scn + 1 == m.cols in function 'perspectiveTransform'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c970821cab36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhorizontalStitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-c970821cab36>\u001b[0m in \u001b[0;36mhorizontalStitch\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mrightStitchedImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstitchFromRight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morderedImages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcenterImageIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morderedImages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcenterImageIndex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mleftStitchedImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstitchFromLeft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrightStitchedImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morderedImages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcenterImageIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mleftStitchedImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c970821cab36>\u001b[0m in \u001b[0;36mstitchFromLeft\u001b[0;34m(image, images)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mwarpedImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarpTwoImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstitchFromLeft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarpedImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6d1902c6381b>\u001b[0m in \u001b[0;36mwarpTwoImages\u001b[0;34m(img1, img2)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpts1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpts2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpts2_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperspectiveTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpts2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtransformedPoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpts2_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#     print(pts2_.reshape(4,2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.1) /tmp/opencv-20190908-76835-1lnncvq/opencv-4.1.1/modules/core/src/matmul.dispatch.cpp:525: error: (-215:Assertion failed) scn + 1 == m.cols in function 'perspectiveTransform'\n"
     ]
    }
   ],
   "source": [
    "def horizontalStitch(images):\n",
    "    stitchOrder, matches = getOrdering(images)\n",
    "    orderedImages = []\n",
    "    for i in stitchOrder:\n",
    "        orderedImages.append(images[i])\n",
    "    centerImageIndex = len(orderedImages)//2\n",
    "    print(centerImageIndex)\n",
    "    \n",
    "#     img = orderedImages[centerImageIndex]\n",
    "#     for i in range(centerImageIndex+1,centerImageIndex+2):#len(orderedImages)):\n",
    "#         img = warpTwoImages(img, orderedImages[i])\n",
    "        \n",
    "#     for i in range(centerImageIndex-1,centerImageIndex-2,-1):#len(orderedImages)):\n",
    "#         img = warpTwoImages(img, orderedImages[i])\n",
    "    \n",
    "    \n",
    "    rightStitchedImage = stitchFromRight(orderedImages[centerImageIndex], orderedImages[centerImageIndex+1:])\n",
    "    leftStitchedImage = stitchFromLeft(rightStitchedImage, orderedImages[:centerImageIndex])\n",
    "    \n",
    "    return leftStitchedImage\n",
    "#     return img\n",
    "\n",
    "    \n",
    "def stitchFromRight(image, images):\n",
    "    if (len(images) == 0):\n",
    "        return image\n",
    "    warpedImg = warpTwoImages(image, images[0])\n",
    "    return stitchFromRight(warpedImg, images[1:])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def stitchFromLeft(image, images):\n",
    "    if (len(images) == 1):\n",
    "        return image\n",
    "    warpedImg = warpTwoImages(image, images[-1])\n",
    "    return stitchFromLeft(warpedImg, images[:-1])\n",
    "    \n",
    "    \n",
    "result = horizontalStitch(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"log.jpg\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = images[2]\n",
    "B = images[1]\n",
    "\n",
    "# generate Gaussian pyramid for A\n",
    "G = A.copy()\n",
    "gpA = [G]\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    G = cv2.pyrDown(G)\n",
    "    gpA.append(G)\n",
    "\n",
    "# generate Gaussian pyramid for B\n",
    "G = B.copy()\n",
    "gpB = [G]\n",
    "for i in range(6):\n",
    "    G = cv2.pyrDown(G)\n",
    "    gpB.append(G)\n",
    "\n",
    "# generate Laplacian Pyramid for A\n",
    "lpA = [gpA[5]]\n",
    "for i in range(5,0,-1):\n",
    "    size = (gpA[i].shape[1], gpA[i].shape[0])\n",
    "    GE = cv2.pyrUp(gpA[i], dstsize = size)\n",
    "    print(type(gpB[i-1]), type(GE))\n",
    "    L = np.subtract(gpA[i-1],GE)\n",
    "    lpA.append(L)\n",
    "\n",
    "# generate Laplacian Pyramid for B\n",
    "lpB = [gpB[5]]\n",
    "for i in range(5,0,-1):\n",
    "    \n",
    "    GE = cv2.pyrUp(gpB[i], dstsize = size)\n",
    "    print(type(gpB[i-1]), type(GE))\n",
    "    L = np.subtract(gpB[i-1],GE)\n",
    "    \n",
    "    lpB.append(L)\n",
    "\n",
    "# Now add left and right halves of images in each level\n",
    "LS = []\n",
    "for la,lb in zip(lpA,lpB):\n",
    "    rows,cols,dpt = la.shape\n",
    "    ls = np.hstack((la[:,0:cols/2], lb[:,cols/2:]))\n",
    "    LS.append(ls)\n",
    "\n",
    "# now reconstruct\n",
    "ls_ = LS[0]\n",
    "for i in range(1,6):\n",
    "    ls_ = cv2.pyrUp(ls_)\n",
    "    ls_ = cv2.add(ls_, LS[i])\n",
    "\n",
    "# image with direct connecting each half\n",
    "real = np.hstack((A[:,:cols/2],B[:,cols/2:]))\n",
    "\n",
    "cv2.imwrite('Pyramid_blending2.jpg',ls_)\n",
    "cv2.imwrite('Direct_blending.jpg',real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
